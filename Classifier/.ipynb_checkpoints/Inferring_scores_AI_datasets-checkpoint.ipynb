{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb94029d",
   "metadata": {},
   "source": [
    "### envs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de9e0597",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the libraries\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import torch\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import  glob\n",
    "import time\n",
    "import albumentations\n",
    "import math\n",
    "from scipy.special import softmax\n",
    "from sklearn.preprocessing import OneHotEncoder# creating instance of one-hot-encoder\n",
    "\n",
    "from models.models import Myresnext50, Myresnext50_algin\n",
    "from train.train_classification import trainer_classification\n",
    "from utils.utils import configure_optimizers\n",
    "from Datasets.DataLoader import Img_DataLoader_pair as Img_DataLoader\n",
    "\n",
    "### PyTorch Imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils import data\n",
    "from torchvision import transforms\n",
    "\n",
    "X_train = glob.glob('../../hemepath_dataset_FINAL/train_val/Cross_Validation/iteration_1/train/*/*')\n",
    "X_val = glob.glob('../../hemepath_dataset_FINAL/train_val/Cross_Validation/iteration_1/val/*/*')\n",
    "\n",
    "labels = [x.split('/')[-2] for x in X_train]\n",
    "cell_types = set(labels)\n",
    "\n",
    "cell_types = list(cell_types)\n",
    "cell_types.sort()\n",
    "\n",
    "cell_types_df = pd.DataFrame(cell_types, columns=['Cell_Types'])# converting type of columns to 'category'\n",
    "cell_types_df['Cell_Types'] = cell_types_df['Cell_Types'].astype('category')# Assigning numerical values and storing in another column\n",
    "cell_types_df['Cell_Types_Cat'] = cell_types_df['Cell_Types'].cat.codes\n",
    "\n",
    "enc = OneHotEncoder(handle_unknown='ignore')# passing bridge-types-cat column (label encoded values of bridge_types)\n",
    "enc_df = pd.DataFrame(enc.fit_transform(cell_types_df[['Cell_Types_Cat']]).toarray())# merge with main df bridge_df on key values\n",
    "cell_types_df = cell_types_df.join(enc_df)\n",
    "\n",
    "#### train_iteration_1 / UCSF\n",
    "\n",
    "transform_pipeline = albumentations.Compose(\n",
    "        [\n",
    "            albumentations.Normalize(mean=(0.5594, 0.4984, 0.6937), std=(0.2701, 0.2835, 0.2176)),\n",
    "\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe1aae0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_test_orig = cellnames[cellnames['dir'].isin(X_test)]\n",
    "cell_types =['False', 'True']\n",
    "def eval_scores(model, test_lists, df, transform, label = None, named_celltype = None, computed_table= False):\n",
    "    model = model.cuda().eval()\n",
    "    Orig_img = Img_DataLoader_pair(img_list=  test_lists, split='viz',df= cell_types_df,transform = transform_pipeline,\n",
    "                                  named_celltype = named_celltype)\n",
    "    shuffle = False\n",
    "    dataloader = DataLoader(Orig_img, batch_size=32, num_workers=2, shuffle=shuffle)\n",
    "\n",
    "\n",
    "    for i, _batch in enumerate(dataloader):\n",
    "\n",
    "        if i == 0:\n",
    "\n",
    "            images = _batch[\"image\"].cuda()\n",
    "            label = _batch[\"label\"].cuda()\n",
    "            match = _batch['agree']\n",
    "            #print(label)\n",
    "            ID    = [x for x in _batch['ID']]\n",
    "            pred_prob = model(images, label)\n",
    "\n",
    "            pred_prob = torch.flatten(pred_prob, start_dim=1).detach().cpu().numpy()\n",
    "            label = match.numpy()  #, start_dim=1).cpu().numpy()\n",
    "        else:\n",
    "            images = _batch[\"image\"].cuda()\n",
    "            _label = _batch[\"label\"].cuda()\n",
    "            _match = _batch['agree']\n",
    "            _ID    = [x for x in _batch['ID']]\n",
    "            _pred_prob = model(images,_label)\n",
    "            \n",
    "\n",
    "            _pred_prob = torch.flatten(_pred_prob, start_dim=1).detach().cpu().numpy()\n",
    "            _label = _match.numpy()  #, start_dim=1).cpu().numpy()  \n",
    "\n",
    "            ID = ID + _ID\n",
    "            pred_prob = np.concatenate((pred_prob, _pred_prob))\n",
    "            label = np.concatenate((label, _label))\n",
    "    label = np.array(label)\n",
    "    _label = np.array(label==0)\n",
    "    label = np.stack([ _label,label])\n",
    "    label = label.T\n",
    "    \n",
    "    pred_prob = softmax(pred_prob, axis=1)\n",
    "    #pred_class_binary = np.where(res,np.max(res, axis =1))\n",
    "\n",
    "    for i in range(pred_prob.shape[0]):\n",
    "        if i == 0:\n",
    "            pred_class = np.where(pred_prob[i] == np.max(pred_prob[i]),1,0).reshape(1,2)\n",
    "        else:\n",
    "            _pred_class = np.where(pred_prob[i] == np.max(pred_prob[i]),1,0).reshape(1,2)\n",
    "            pred_class = np.concatenate((pred_class, _pred_class), axis =0)\n",
    "    \n",
    "    ID = [x for x in ID]\n",
    "    print(pred_prob.shape)\n",
    "    print(pred_class.shape)\n",
    "    pred_class = pd.DataFrame.from_records(pred_class, \n",
    "                                       columns= cell_types,\n",
    "                                      index = ID)\n",
    "    pred_prob = pd.DataFrame.from_records(pred_prob, \n",
    "                                           columns= cell_types,\n",
    "                                          index = ID)\n",
    "    label = pd.DataFrame.from_records(label, \n",
    "                                           columns= cell_types,\n",
    "                                          index = ID)\n",
    "    \n",
    "    if computed_table:\n",
    "        multiclass = evaluation_metrics_multiclass(label, pred_prob, pred_class)\n",
    "\n",
    "        #multiclass = evaluation_metrics_multiclass(label, pred_prob, pred_class)\n",
    "\n",
    "        df = pd.DataFrame.from_dict(multiclass)\n",
    "        df.index = ['AUC','F1','Acc','Precision','Recall']\n",
    "        df = df.T\n",
    "        df_summary = df.copy()\n",
    "        df_summary.loc['Mean'] = np.average(df, axis =0)\n",
    "        df_summary.loc['Medium'] = np.median(df, axis =0)\n",
    "        return df_summary, pred_class,pred_prob,label\n",
    "    else:\n",
    "        ### only logis\n",
    "        return pred_prob, label, ID"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e083ab7",
   "metadata": {},
   "source": [
    "#### load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3a157bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Img_DataLoader_pair(data.Dataset):\n",
    "    def __init__(self, img_list='', in_dim=3, split='train', transform=False, in_size=96, df=None, encoder=None,\n",
    "                 if_external=False, df_features = None, named_celltype = None):\n",
    "        super(Img_DataLoader_pair, self).__init__()\n",
    "        self.split = split\n",
    "        self.in_dim = in_dim\n",
    "        self.transform = transform\n",
    "        self.filelist = img_list\n",
    "        self.in_size = in_size\n",
    "        self.file_paths = img_list\n",
    "        self.transform = transform\n",
    "        self.df = df\n",
    "        self.encoder = encoder\n",
    "        self.if_external = if_external\n",
    "        self.df_features = df_features\n",
    "    def __len__(self):\n",
    "        return len(self.file_paths)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        sample = dict()\n",
    "        img_path = self.file_paths[index]\n",
    "        # prepare image\n",
    "        orig_img = cv2.imread(img_path)\n",
    "        image = cv2.cvtColor(orig_img, cv2.COLOR_BGR2RGB)\n",
    "        '''\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        image[:,:, 0] = gray\n",
    "        image[:,:, 1] = gray\n",
    "        image[:,:, 2] = gray\n",
    "        '''\n",
    "        ###################################\n",
    "\n",
    "        ###################################\n",
    "        if self.transform is not None:\n",
    "            try:\n",
    "                img = self.transform(image=image)[\"image\"]\n",
    "            except:\n",
    "                assert 1 == 2, 'something wrong'\n",
    "                print(image)\n",
    "\n",
    "        label = img_path.split('/')[-2]\n",
    "        match = 1\n",
    "\n",
    "        # permutate\n",
    "        if named_celltype is not None:\n",
    "            \n",
    "            if label == named_celltype:\n",
    "                pass\n",
    "            else:\n",
    "                label = named_celltype\n",
    "                match = 0\n",
    "        else:          \n",
    "            permute = np.random.choice([0, 1])\n",
    "            lists = self.df['Cell_Types'].tolist()\n",
    "            if permute == 1:\n",
    "                lists.remove(label)\n",
    "\n",
    "                label = random.choice(lists)\n",
    "                match = 0\n",
    "            else:\n",
    "                pass\n",
    "        # print(img.shape)\n",
    "        #if self.if_external:\n",
    "        if img.shape[0]!=64:\n",
    "            img = img[16:80,16:80,:]\n",
    "        #img = cv2.resize(img, (64, 64), interpolation=cv2.INTER_AREA)\n",
    "        # img = img.reshape(3,96,96)\n",
    "        high_level_name = label\n",
    "        img = np.einsum('ijk->kij', img)\n",
    "\n",
    "        if self.split != \"compute\":  # Use compute if you only want the prediction results. if you do this, make sure you don't shuffle the data\n",
    "\n",
    "            print(hi)\n",
    "            mask = self.df[self.df['Cell_Types'] == high_level_name].iloc[:, 2:].to_numpy()\n",
    "            mask = mask.reshape(23,)\n",
    "            sample[\"label\"] = torch.from_numpy(mask).float()  # one hot encoder\n",
    "\n",
    "\n",
    "        sample[\"image\"] = torch.from_numpy(img).float()  # self.encoder(torch.from_numpy(img).float())\n",
    "        sample[\"ID\"] = img_path\n",
    "        sample[\"agree\"] = torch.from_numpy(np.array(match)).long()\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8056dc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/aa-ssun2-cmp/.cache/torch/hub/pytorch_vision_v0.10.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnext50_pretrained = torch.hub.load('pytorch/vision:v0.10.0', 'resnext50_32x4d')\n",
    "My_model = Myresnext50(my_pretrained_model=resnext50_pretrained, num_classes=23)\n",
    "\n",
    "\n",
    "\n",
    "from collections import OrderedDict\n",
    "def remove_data_parallel(old_state_dict):\n",
    "    new_state_dict = OrderedDict()\n",
    "\n",
    "    for k, v in old_state_dict.items():\n",
    "        name = k[7:]  # remove `module.`\n",
    "\n",
    "        new_state_dict[name] = v\n",
    "\n",
    "    return new_state_dict\n",
    "\n",
    "\n",
    "\n",
    "#My_model.load_state_dict(checkpoint, strict=True)\n",
    "my_extended_model = Myresnext50_algin(my_pretrained_model= resnext50_pretrained)\n",
    "checkpoint_PATH = '/data/aa-ssun2-cmp/improved-diffusion/Hemo_DL/scoring_function_models/allfeedback/checkpoint_best_iteration3.ckpt'\n",
    "checkpoint = torch.load(checkpoint_PATH)\n",
    "checkpoint = remove_data_parallel(checkpoint['model_state_dict'])\n",
    "my_extended_model.load_state_dict(checkpoint, strict=True)\n",
    "#### change the dataloader so that it can assign the label I want to give to it\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bab9ef0",
   "metadata": {},
   "source": [
    "### compute scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e2be77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### batch_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c31b4eeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B1\n",
      "B2\n",
      "E1\n",
      "E4\n",
      "ER1\n",
      "ER2\n",
      "ER3\n",
      "ER4\n",
      "ER5\n",
      "ER6\n",
      "L2\n",
      "L4\n",
      "M1\n",
      "M2\n",
      "M3\n",
      "M4\n",
      "M5\n",
      "M6\n",
      "MO2\n",
      "PL2\n",
      "PL3\n",
      "U1\n",
      "U4\n"
     ]
    }
   ],
   "source": [
    "Image_dirs = []\n",
    "scores = []\n",
    "for _celltype in cell_types_df['Cell_Types'].tolist():\n",
    "    print(_celltype)\n",
    "    X_test_per_cell =  glob.glob('../dm_hemedata/train/'+_celltype+'/*')#hemepath_dataset_FINAL/\n",
    "    \n",
    "    \n",
    "    for named_celltype in [_celltype]:\n",
    "        \n",
    "        pred_prob, pred_label, IDs = eval(my_extended_model, X_test_per_cell, cell_types_df, transform_pipeline,\n",
    "                                             named_celltype=named_celltype)\n",
    "        scores+=pred_prob['True'].tolist()\n",
    "        Image_dirs+=IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47235d70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B1\n",
      "B2\n",
      "E1\n",
      "E4\n",
      "ER1\n",
      "ER2\n",
      "ER3\n",
      "ER4\n",
      "ER5\n",
      "ER6\n",
      "L2\n",
      "L4\n",
      "M1\n",
      "M2\n",
      "M3\n",
      "M4\n",
      "M5\n",
      "M6\n",
      "MO2\n",
      "PL2\n",
      "PL3\n",
      "U1\n",
      "U4\n"
     ]
    }
   ],
   "source": [
    "for _celltype in cell_types_df['Cell_Types'].tolist():\n",
    "    print(_celltype)\n",
    "    X_test_per_cell =  glob.glob('../dm_hemedata_guided/'+_celltype+'/*')#hemepath_dataset_FINAL/\n",
    "    \n",
    "    \n",
    "    for named_celltype in [_celltype]:\n",
    "        \n",
    "        pred_prob, pred_label, IDs = eval(my_extended_model, X_test_per_cell, cell_types_df, transform_pipeline,\n",
    "                                             named_celltype=named_celltype)\n",
    "        scores+=pred_prob['True'].tolist()\n",
    "        Image_dirs+=IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2b50d33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B1\n",
      "B2\n",
      "E1\n",
      "E4\n",
      "ER1\n",
      "ER2\n",
      "ER3\n",
      "ER4\n",
      "ER5\n",
      "ER6\n",
      "L2\n",
      "L4\n",
      "M1\n",
      "M2\n",
      "M3\n",
      "M4\n",
      "M5\n",
      "M6\n",
      "MO2\n",
      "PL2\n",
      "PL3\n",
      "U1\n",
      "U4\n"
     ]
    }
   ],
   "source": [
    "for _celltype in cell_types_df['Cell_Types'].tolist():\n",
    "    print(_celltype)\n",
    "    X_test_per_cell =  glob.glob('../dm_hemedata_test/clinician_guide/finetuned/'+_celltype+'/*')#hemepath_dataset_FINAL/\n",
    "    \n",
    "    \n",
    "    for named_celltype in [_celltype]:\n",
    "        \n",
    "        pred_prob, pred_label, IDs = eval(my_extended_model, X_test_per_cell, cell_types_df, transform_pipeline,\n",
    "                                             named_celltype=named_celltype)\n",
    "        scores+=pred_prob['True'].tolist()\n",
    "        Image_dirs+=IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef178a7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B1\n",
      "B2\n",
      "E1\n",
      "E4\n",
      "ER1\n",
      "ER2\n",
      "ER3\n",
      "ER4\n",
      "ER5\n",
      "ER6\n",
      "L2\n",
      "L4\n",
      "M1\n",
      "M2\n",
      "M3\n",
      "M4\n",
      "M5\n",
      "M6\n",
      "MO2\n",
      "PL2\n",
      "PL3\n",
      "U1\n",
      "U4\n"
     ]
    }
   ],
   "source": [
    "for _celltype in cell_types_df['Cell_Types'].tolist():\n",
    "    print(_celltype)\n",
    "    X_test_per_cell =  glob.glob('../dm_hemedata_test/clinician_guide/batch1_128/'+_celltype+'/*')#hemepath_dataset_FINAL/\n",
    "    \n",
    "    \n",
    "    for named_celltype in [_celltype]:\n",
    "        \n",
    "        pred_prob, pred_label, IDs = eval(my_extended_model, X_test_per_cell, cell_types_df, transform_pipeline,\n",
    "                                             named_celltype=named_celltype)\n",
    "        scores+=pred_prob['True'].tolist()\n",
    "        Image_dirs+=IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a1a052d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B1\n",
      "B2\n",
      "E1\n",
      "E4\n",
      "ER1\n",
      "ER2\n",
      "ER3\n",
      "ER4\n",
      "ER5\n",
      "ER6\n",
      "L2\n",
      "L4\n",
      "M1\n",
      "M2\n",
      "M3\n",
      "M4\n",
      "M5\n",
      "M6\n",
      "MO2\n",
      "PL2\n",
      "PL3\n",
      "U1\n",
      "U4\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for _celltype in cell_types_df['Cell_Types'].tolist():\n",
    "    print(_celltype)\n",
    "    X_test_per_cell =  glob.glob('../dm_hemedata_test/clinician_guide/batch2_128/'+_celltype+'/*')#hemepath_dataset_FINAL/\n",
    "    \n",
    "    \n",
    "    for named_celltype in [_celltype]:\n",
    "        \n",
    "        pred_prob, pred_label, IDs = eval(my_extended_model, X_test_per_cell, cell_types_df, transform_pipeline,\n",
    "                                             named_celltype=named_celltype)\n",
    "        scores+=pred_prob['True'].tolist()\n",
    "        Image_dirs+=IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4781b4d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2c574000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B1\n",
      "B2\n",
      "E1\n",
      "E4\n",
      "ER1\n",
      "ER2\n",
      "ER3\n",
      "ER4\n",
      "ER5\n",
      "ER6\n",
      "L2\n",
      "L4\n",
      "M1\n",
      "M2\n",
      "M3\n",
      "M4\n",
      "M5\n",
      "M6\n",
      "MO2\n",
      "PL2\n",
      "PL3\n",
      "U1\n",
      "U4\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "Image_dirs = []\n",
    "celltype_lists = []\n",
    "for _celltype in cell_types_df['Cell_Types'].tolist():\n",
    "    print(_celltype)\n",
    "    X_test_per_cell =  glob.glob('../dm_hemedata/PreTrainedModelset_v2/'+_celltype+'/*')#hemepath_dataset_FINAL/\n",
    "    \n",
    "    \n",
    "    for named_celltype in [_celltype]:\n",
    "        \n",
    "        pred_prob, pred_label, IDs = eval(my_extended_model, X_test_per_cell, cell_types_df, transform_pipeline,\n",
    "                                             named_celltype=named_celltype)\n",
    "        scores+=pred_prob['True'].tolist()\n",
    "        Image_dirs+=IDs\n",
    "        celltype_lists += [_celltype]*len(X_test_per_cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0e7a7184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B1\n",
      "B2\n",
      "E1\n",
      "E4\n",
      "ER1\n",
      "ER2\n",
      "ER3\n",
      "ER4\n",
      "ER5\n",
      "ER6\n",
      "L2\n",
      "L4\n",
      "M1\n",
      "M2\n",
      "M3\n",
      "M4\n",
      "M5\n",
      "M6\n",
      "MO2\n",
      "PL2\n",
      "PL3\n",
      "U1\n",
      "U4\n"
     ]
    }
   ],
   "source": [
    "for _celltype in cell_types_df['Cell_Types'].tolist():\n",
    "    print(_celltype)\n",
    "    X_test_per_cell =  glob.glob('../dm_hemedata/FinetunedModel_v0/'+_celltype+'_*')#hemepath_dataset_FINAL/\n",
    "    \n",
    "    \n",
    "    for named_celltype in [_celltype]:\n",
    "        \n",
    "        pred_prob, pred_label, IDs = eval(my_extended_model, X_test_per_cell, cell_types_df, transform_pipeline,\n",
    "                                             named_celltype=named_celltype)\n",
    "        scores+=pred_prob['True'].tolist()\n",
    "        Image_dirs+=IDs\n",
    "        celltype_lists += [_celltype]*len(X_test_per_cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4d93f554",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25230"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Image_dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "90a58fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def processing(x):\n",
    "    if x < 0.9:\n",
    "        return min(0.01,x)\n",
    "    else:\n",
    "        assert x>= 0.90, 'wrong'\n",
    "        if x >0.99:\n",
    "            return 0.1 + 9 * (x - 0.9)\n",
    "        else: \n",
    "            return 0.1 + 5 * (x - 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4eb7cfb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df = pd.DataFrame([], columns=['image_dirs','expert_scores'])\n",
    "df['image_dirs'] = Image_dirs\n",
    "df['expert_scores'] = scores\n",
    "rewards = []\n",
    "rewards = [processing(x) for x in scores]\n",
    "df['rewards'] = rewards\n",
    "df['celltype'] = celltype_lists\n",
    "df['ID'] = df['image_dirs'].str.split('/').str[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b0dfcece",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_dirs</th>\n",
       "      <th>expert_scores</th>\n",
       "      <th>rewards</th>\n",
       "      <th>celltype</th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../dm_hemedata/PreTrainedModelset_v2/B1/53.png</td>\n",
       "      <td>0.123331</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>B1</td>\n",
       "      <td>53.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../dm_hemedata/PreTrainedModelset_v2/B1/238.png</td>\n",
       "      <td>0.139862</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>B1</td>\n",
       "      <td>238.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../dm_hemedata/PreTrainedModelset_v2/B1/152.png</td>\n",
       "      <td>0.032216</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>B1</td>\n",
       "      <td>152.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../dm_hemedata/PreTrainedModelset_v2/B1/339.png</td>\n",
       "      <td>0.853531</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>B1</td>\n",
       "      <td>339.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../dm_hemedata/PreTrainedModelset_v2/B1/286.png</td>\n",
       "      <td>0.000215</td>\n",
       "      <td>0.000215</td>\n",
       "      <td>B1</td>\n",
       "      <td>286.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25225</th>\n",
       "      <td>../dm_hemedata/FinetunedModel_v0/U4_279c116.png</td>\n",
       "      <td>0.971710</td>\n",
       "      <td>0.458552</td>\n",
       "      <td>U4</td>\n",
       "      <td>U4_279c116.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25226</th>\n",
       "      <td>../dm_hemedata/FinetunedModel_v0/U4_94c53.png</td>\n",
       "      <td>0.031066</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>U4</td>\n",
       "      <td>U4_94c53.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25227</th>\n",
       "      <td>../dm_hemedata/FinetunedModel_v0/U4_252c66.png</td>\n",
       "      <td>0.002382</td>\n",
       "      <td>0.002382</td>\n",
       "      <td>U4</td>\n",
       "      <td>U4_252c66.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25228</th>\n",
       "      <td>../dm_hemedata/FinetunedModel_v0/U4_357c36.png</td>\n",
       "      <td>0.991502</td>\n",
       "      <td>0.923517</td>\n",
       "      <td>U4</td>\n",
       "      <td>U4_357c36.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25229</th>\n",
       "      <td>../dm_hemedata/FinetunedModel_v0/U4_384c27.png</td>\n",
       "      <td>0.069873</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>U4</td>\n",
       "      <td>U4_384c27.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25230 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            image_dirs  expert_scores  \\\n",
       "0       ../dm_hemedata/PreTrainedModelset_v2/B1/53.png       0.123331   \n",
       "1      ../dm_hemedata/PreTrainedModelset_v2/B1/238.png       0.139862   \n",
       "2      ../dm_hemedata/PreTrainedModelset_v2/B1/152.png       0.032216   \n",
       "3      ../dm_hemedata/PreTrainedModelset_v2/B1/339.png       0.853531   \n",
       "4      ../dm_hemedata/PreTrainedModelset_v2/B1/286.png       0.000215   \n",
       "...                                                ...            ...   \n",
       "25225  ../dm_hemedata/FinetunedModel_v0/U4_279c116.png       0.971710   \n",
       "25226    ../dm_hemedata/FinetunedModel_v0/U4_94c53.png       0.031066   \n",
       "25227   ../dm_hemedata/FinetunedModel_v0/U4_252c66.png       0.002382   \n",
       "25228   ../dm_hemedata/FinetunedModel_v0/U4_357c36.png       0.991502   \n",
       "25229   ../dm_hemedata/FinetunedModel_v0/U4_384c27.png       0.069873   \n",
       "\n",
       "        rewards celltype              ID  \n",
       "0      0.010000       B1          53.png  \n",
       "1      0.010000       B1         238.png  \n",
       "2      0.010000       B1         152.png  \n",
       "3      0.010000       B1         339.png  \n",
       "4      0.000215       B1         286.png  \n",
       "...         ...      ...             ...  \n",
       "25225  0.458552       U4  U4_279c116.png  \n",
       "25226  0.010000       U4    U4_94c53.png  \n",
       "25227  0.002382       U4   U4_252c66.png  \n",
       "25228  0.923517       U4   U4_357c36.png  \n",
       "25229  0.010000       U4   U4_384c27.png  \n",
       "\n",
       "[25230 rows x 5 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4c3e5ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "adff53d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "computed_IDs= []\n",
    "df_sorted = df.sort_values(['celltype'])\n",
    "for _celltype in cell_types_df['Cell_Types'].tolist():\n",
    "    df_sorted_sub = df_sorted[df_sorted['celltype']==_celltype]\n",
    "    IDs = list(range(df_sorted_sub.shape[0]))\n",
    "    Start = 0\n",
    "    Stop = df_sorted_sub.shape[0]\n",
    "    limit = df_sorted_sub.shape[0]\n",
    "    IDs = [random.randint(Start, Stop) for iter in range(limit)]\n",
    "    computed_IDs+=[''.join(random.choices(string.ascii_letters, k=10))+'.png' for x in df_sorted_sub['ID']]\n",
    "    #computed_IDs+=[(str(x)+'c'+y) if 'c' not in y else  (str(x)+'c'+y).replace(_celltype+'_','') for (x,y) in zip(IDs, df_sorted_sub['ID'])]\n",
    "df_sorted['ID']  = computed_IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ac39524c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_dirs</th>\n",
       "      <th>expert_scores</th>\n",
       "      <th>rewards</th>\n",
       "      <th>celltype</th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../dm_hemedata/PreTrainedModelset_v2/B1/53.png</td>\n",
       "      <td>0.123331</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>B1</td>\n",
       "      <td>TfvShGyUaG.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12363</th>\n",
       "      <td>../dm_hemedata/FinetunedModel_v0/B1_285c23.png</td>\n",
       "      <td>0.929201</td>\n",
       "      <td>0.246006</td>\n",
       "      <td>B1</td>\n",
       "      <td>duvMKhOxcb.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12364</th>\n",
       "      <td>../dm_hemedata/FinetunedModel_v0/B1_202c45.png</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>B1</td>\n",
       "      <td>YfGqqnhdgE.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12365</th>\n",
       "      <td>../dm_hemedata/FinetunedModel_v0/B1_118c36.png</td>\n",
       "      <td>0.993602</td>\n",
       "      <td>0.942418</td>\n",
       "      <td>B1</td>\n",
       "      <td>nmbPqQkWAH.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12366</th>\n",
       "      <td>../dm_hemedata/FinetunedModel_v0/B1_108c53.png</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>B1</td>\n",
       "      <td>lFSpFKUPYN.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11622</th>\n",
       "      <td>../dm_hemedata/PreTrainedModelset_v2/U4/467.png</td>\n",
       "      <td>0.958537</td>\n",
       "      <td>0.392685</td>\n",
       "      <td>U4</td>\n",
       "      <td>zRUyXXmEYw.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11623</th>\n",
       "      <td>../dm_hemedata/PreTrainedModelset_v2/U4/125.png</td>\n",
       "      <td>0.062788</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>U4</td>\n",
       "      <td>xGuqpwAKqO.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11624</th>\n",
       "      <td>../dm_hemedata/PreTrainedModelset_v2/U4/368.png</td>\n",
       "      <td>0.000958</td>\n",
       "      <td>0.000958</td>\n",
       "      <td>U4</td>\n",
       "      <td>WmAuiuuOgm.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11618</th>\n",
       "      <td>../dm_hemedata/PreTrainedModelset_v2/U4/273.png</td>\n",
       "      <td>0.984705</td>\n",
       "      <td>0.523527</td>\n",
       "      <td>U4</td>\n",
       "      <td>FCfCQTFpPF.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25229</th>\n",
       "      <td>../dm_hemedata/FinetunedModel_v0/U4_384c27.png</td>\n",
       "      <td>0.069873</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>U4</td>\n",
       "      <td>PfBQiyZVeS.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25230 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            image_dirs  expert_scores  \\\n",
       "0       ../dm_hemedata/PreTrainedModelset_v2/B1/53.png       0.123331   \n",
       "12363   ../dm_hemedata/FinetunedModel_v0/B1_285c23.png       0.929201   \n",
       "12364   ../dm_hemedata/FinetunedModel_v0/B1_202c45.png       0.000059   \n",
       "12365   ../dm_hemedata/FinetunedModel_v0/B1_118c36.png       0.993602   \n",
       "12366   ../dm_hemedata/FinetunedModel_v0/B1_108c53.png       0.000003   \n",
       "...                                                ...            ...   \n",
       "11622  ../dm_hemedata/PreTrainedModelset_v2/U4/467.png       0.958537   \n",
       "11623  ../dm_hemedata/PreTrainedModelset_v2/U4/125.png       0.062788   \n",
       "11624  ../dm_hemedata/PreTrainedModelset_v2/U4/368.png       0.000958   \n",
       "11618  ../dm_hemedata/PreTrainedModelset_v2/U4/273.png       0.984705   \n",
       "25229   ../dm_hemedata/FinetunedModel_v0/U4_384c27.png       0.069873   \n",
       "\n",
       "        rewards celltype              ID  \n",
       "0      0.010000       B1  TfvShGyUaG.png  \n",
       "12363  0.246006       B1  duvMKhOxcb.png  \n",
       "12364  0.000059       B1  YfGqqnhdgE.png  \n",
       "12365  0.942418       B1  nmbPqQkWAH.png  \n",
       "12366  0.000003       B1  lFSpFKUPYN.png  \n",
       "...         ...      ...             ...  \n",
       "11622  0.392685       U4  zRUyXXmEYw.png  \n",
       "11623  0.010000       U4  xGuqpwAKqO.png  \n",
       "11624  0.000958       U4  WmAuiuuOgm.png  \n",
       "11618  0.523527       U4  FCfCQTFpPF.png  \n",
       "25229  0.010000       U4  PfBQiyZVeS.png  \n",
       "\n",
       "[25230 rows x 5 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "53db870c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SKLfh\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import string\n",
    "\n",
    "print(''.join(random.choices(string.ascii_letters, k=10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f9d0b6f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25230"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(df_sorted['ID']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "07848d15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25230"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258f4c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "FinetunedModel_v0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4c9859bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25230/25230 [45:27<00:00,  9.25it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "for _dir in tqdm(df_sorted['image_dirs'].tolist()):\n",
    "    \n",
    "    ID = df_sorted[df_sorted['image_dirs']==_dir]['ID'].iloc[0]\n",
    "    celltype = df_sorted[df_sorted['image_dirs']==_dir]['celltype'].iloc[0]\n",
    "    os.system('cp '+_dir + ' ../dm_hemedata/FinetunedModel_v1/'+celltype+'_'+ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e3a8cee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _id in glob.glob('../dm_hemedata_test/clinician_guide/trial_2/*'):\n",
    "    M5id = _id.split('_')[-1]\n",
    "    os.system('cp '+_id+' '+'../dm_hemedata/PreTrainedModelset_v2/M5/'+M5id)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7b30b12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25228"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "len(glob.glob('../dm_hemedata/FinetunedModel_v1/*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "da8d9d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sorted.to_csv('../dm_hemedata/expert_scores_FinetunedModel_v1.tsv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f47a0282",
   "metadata": {},
   "source": [
    "### Let's try to change the percentage feeding to the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f79aff9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25230, 6)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../dm_hemedata/expert_scores_v1.tsv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c2140658",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>image_dirs</th>\n",
       "      <th>expert_scores</th>\n",
       "      <th>rewards</th>\n",
       "      <th>celltype</th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>../dm_hemedata/PreTrainedModelset_v2/B1/53.png</td>\n",
       "      <td>0.123331</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>B1</td>\n",
       "      <td>TfvShGyUaG.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12363</td>\n",
       "      <td>../dm_hemedata/FinetunedModel_v0/B1_285c23.png</td>\n",
       "      <td>0.929201</td>\n",
       "      <td>0.246006</td>\n",
       "      <td>B1</td>\n",
       "      <td>duvMKhOxcb.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12364</td>\n",
       "      <td>../dm_hemedata/FinetunedModel_v0/B1_202c45.png</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>B1</td>\n",
       "      <td>YfGqqnhdgE.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12365</td>\n",
       "      <td>../dm_hemedata/FinetunedModel_v0/B1_118c36.png</td>\n",
       "      <td>0.993602</td>\n",
       "      <td>0.942418</td>\n",
       "      <td>B1</td>\n",
       "      <td>nmbPqQkWAH.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12366</td>\n",
       "      <td>../dm_hemedata/FinetunedModel_v0/B1_108c53.png</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>B1</td>\n",
       "      <td>lFSpFKUPYN.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                      image_dirs  expert_scores  \\\n",
       "0           0  ../dm_hemedata/PreTrainedModelset_v2/B1/53.png       0.123331   \n",
       "1       12363  ../dm_hemedata/FinetunedModel_v0/B1_285c23.png       0.929201   \n",
       "2       12364  ../dm_hemedata/FinetunedModel_v0/B1_202c45.png       0.000059   \n",
       "3       12365  ../dm_hemedata/FinetunedModel_v0/B1_118c36.png       0.993602   \n",
       "4       12366  ../dm_hemedata/FinetunedModel_v0/B1_108c53.png       0.000003   \n",
       "\n",
       "    rewards celltype              ID  \n",
       "0  0.010000       B1  TfvShGyUaG.png  \n",
       "1  0.246006       B1  duvMKhOxcb.png  \n",
       "2  0.000059       B1  YfGqqnhdgE.png  \n",
       "3  0.942418       B1  nmbPqQkWAH.png  \n",
       "4  0.000003       B1  lFSpFKUPYN.png  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a358e21",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "folder = '../dm_hemedata/Finetuned_dataset_v1/'\n",
    "imgdirs = [folder+x+'_'+y for (x,y) in zip(df['celltype'].tolist(), df['ID'].tolist())]\n",
    "named_celltype = [x.split('/')[-1].split('_')[0] for x in imgdirs]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a29daa56",
   "metadata": {},
   "source": [
    "### 0.1 feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8318fef6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_extended_model = Myresnext50_algin(my_pretrained_model= resnext50_pretrained)\n",
    "checkpoint_PATH = '/data/aa-ssun2-cmp/improved-diffusion/Hemo_DL/scoring_function_models/scoring_function_v0.1/checkpoint_best_iteration3.ckpt'\n",
    "checkpoint = torch.load(checkpoint_PATH)\n",
    "checkpoint = remove_data_parallel(checkpoint['model_state_dict'])\n",
    "my_extended_model.load_state_dict(checkpoint, strict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "46c7a5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Img_DataLoader_pair(data.Dataset):\n",
    "    def __init__(self, img_list='', in_dim=3, split='train', transform=False, in_size=96, df=None, encoder=None,\n",
    "                 if_external=False, df_features = None, named_celltype = None):\n",
    "        super(Img_DataLoader_pair, self).__init__()\n",
    "        self.split = split\n",
    "        self.in_dim = in_dim\n",
    "        self.transform = transform\n",
    "        self.filelist = img_list\n",
    "        self.in_size = in_size\n",
    "        self.file_paths = img_list\n",
    "        self.transform = transform\n",
    "        self.df = df\n",
    "        self.encoder = encoder\n",
    "        self.if_external = if_external\n",
    "        self.df_features = df_features\n",
    "        self.named_celltype = named_celltype\n",
    "    def __len__(self):\n",
    "        return len(self.file_paths)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        sample = dict()\n",
    "        img_path = self.file_paths[index]\n",
    "        high_level_name = self.named_celltype[index]\n",
    "        # prepare image\n",
    "        orig_img = cv2.imread(img_path)\n",
    "        image = cv2.cvtColor(orig_img, cv2.COLOR_BGR2RGB)\n",
    "        '''\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        image[:,:, 0] = gray\n",
    "        image[:,:, 1] = gray\n",
    "        image[:,:, 2] = gray\n",
    "        '''\n",
    "        ###################################\n",
    "\n",
    "        ###################################\n",
    "        if self.transform is not None:\n",
    "            try:\n",
    "                img = self.transform(image=image)[\"image\"]\n",
    "            except:\n",
    "                assert 1 == 2, 'something wrong'\n",
    "                print(image)\n",
    "\n",
    "        label = img_path.split('/')[-1].split('_')[0]\n",
    "        match = 1\n",
    "\n",
    "        # permutate\n",
    "        if named_celltype is not None:\n",
    "            \n",
    "            if label == named_celltype:\n",
    "                pass\n",
    "            else:\n",
    "                label = named_celltype\n",
    "                match = 0\n",
    "        else:          \n",
    "            permute = np.random.choice([0, 1])\n",
    "            lists = self.df['Cell_Types'].tolist()\n",
    "            if permute == 1:\n",
    "                lists.remove(label)\n",
    "\n",
    "                label = random.choice(lists)\n",
    "                match = 0\n",
    "            else:\n",
    "                pass\n",
    "        # print(img.shape)\n",
    "        #if self.if_external:\n",
    "        if img.shape[0]!=64:\n",
    "            img = img[16:80,16:80,:]\n",
    "        #img = cv2.resize(img, (64, 64), interpolation=cv2.INTER_AREA)\n",
    "        # img = img.reshape(3,96,96)\n",
    "        \n",
    "        img = np.einsum('ijk->kij', img)\n",
    "        \n",
    "        if self.split != \"compute\":  # Use compute if you only want the prediction results. if you do this, make sure you don't shuffle the data\n",
    "            mask = self.df[self.df['Cell_Types'] == high_level_name].iloc[:, 2:].to_numpy()\n",
    "            mask = mask.reshape(23,)\n",
    "            sample[\"label\"] = torch.from_numpy(mask).float()  # one hot encoder\n",
    "\n",
    "\n",
    "        sample[\"image\"] = torch.from_numpy(img).float()  # self.encoder(torch.from_numpy(img).float())\n",
    "        sample[\"ID\"] = img_path\n",
    "        sample[\"agree\"] = torch.from_numpy(np.array(match)).long()\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "dc4e3b64",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cell_Types</th>\n",
       "      <th>Cell_Types_Cat</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>...</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Cell_Types  Cell_Types_Cat    0    1    2    3    4    5    6    7  ...  \\\n",
       "0         B1               0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "\n",
       "    13   14   15   16   17   18   19   20   21   22  \n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[1 rows x 25 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "662d8fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "Image_dirs = []\n",
    "celltype_lists = []\n",
    "\n",
    "        \n",
    "pred_prob, pred_label, IDs = eval_scores(my_extended_model, imgdirs, cell_types_df, transform_pipeline,\n",
    "                                             named_celltype=named_celltype)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "eadcebb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def processing(x):\n",
    "    if x < 0.9:\n",
    "        return min(0.01,x)\n",
    "    else:\n",
    "        assert x>= 0.90, 'wrong'\n",
    "        if x >0.99:\n",
    "            return 0.1 + 9 * (x - 0.9)\n",
    "        else: \n",
    "            return 0.1 + 5 * (x - 0.9)\n",
    "        \n",
    "scores=pred_prob['True'].tolist()\n",
    "Image_dirs=IDs\n",
    "celltype_lists = named_celltype\n",
    "\n",
    "df = pd.DataFrame([], columns=['image_dirs','expert_scores'])\n",
    "df['image_dirs'] = Image_dirs\n",
    "df['expert_scores'] = scores\n",
    "rewards = []\n",
    "rewards = [processing(x) for x in scores]\n",
    "df['rewards'] = rewards\n",
    "df['celltype'] = celltype_lists\n",
    "df['ID'] = df['image_dirs'].str.split('/').str[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f5266dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../dm_hemedata/expert_scores_FinetunedModel_v0.1.tsv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e7093f",
   "metadata": {},
   "source": [
    "### 0.2 feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "748723b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls /data/aa-ssun2-cmp/improved-diffusion/Hemo_DL/scoring_function_models/scoring_function_v0.2/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e42b2aec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "my_extended_model = Myresnext50_algin(my_pretrained_model= resnext50_pretrained)\n",
    "checkpoint_PATH = '/data/aa-ssun2-cmp/improved-diffusion/Hemo_DL/scoring_function_models/scoring_function_v0.2/checkpoint_best_iteration3.ckpt'\n",
    "checkpoint = torch.load(checkpoint_PATH)\n",
    "checkpoint = remove_data_parallel(checkpoint['model_state_dict'])\n",
    "my_extended_model.load_state_dict(checkpoint, strict=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6770f0",
   "metadata": {},
   "source": [
    "### 0.5 feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f4dc97e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_extended_model = Myresnext50_algin(my_pretrained_model= resnext50_pretrained)\n",
    "checkpoint_PATH = '/data/aa-ssun2-cmp/improved-diffusion/Hemo_DL/scoring_function_models/scoring_function_v0.5/checkpoint_best_iteration3.ckpt'\n",
    "checkpoint = torch.load(checkpoint_PATH)\n",
    "checkpoint = remove_data_parallel(checkpoint['model_state_dict'])\n",
    "my_extended_model.load_state_dict(checkpoint, strict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2a19bb3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "Image_dirs = []\n",
    "celltype_lists = []\n",
    "\n",
    "        \n",
    "pred_prob, pred_label, IDs = eval_scores(my_extended_model, imgdirs, cell_types_df, transform_pipeline,\n",
    "                                             named_celltype=named_celltype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "961429e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def processing(x):\n",
    "    if x < 0.9:\n",
    "        return min(0.01,x)\n",
    "    else:\n",
    "        assert x>= 0.90, 'wrong'\n",
    "        if x >0.99:\n",
    "            return 0.1 + 9 * (x - 0.9)\n",
    "        else: \n",
    "            return 0.1 + 5 * (x - 0.9)\n",
    "        \n",
    "scores=pred_prob['True'].tolist()\n",
    "Image_dirs=IDs\n",
    "celltype_lists = named_celltype\n",
    "\n",
    "df = pd.DataFrame([], columns=['image_dirs','expert_scores'])\n",
    "df['image_dirs'] = Image_dirs\n",
    "df['expert_scores'] = scores\n",
    "rewards = []\n",
    "rewards = [processing(x) for x in scores]\n",
    "df['rewards'] = rewards\n",
    "df['celltype'] = celltype_lists\n",
    "df['ID'] = df['image_dirs'].str.split('/').str[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "bd8eae05",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../dm_hemedata/expert_scores_FinetunedModel_v0.5.tsv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334807e7",
   "metadata": {},
   "source": [
    "# without weakfeedback"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba8e9e8",
   "metadata": {},
   "source": [
    "#### 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "76599163",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_extended_model = Myresnext50_algin(my_pretrained_model= resnext50_pretrained)\n",
    "checkpoint_PATH = '/data/aa-ssun2-cmp/improved-diffusion/Hemo_DL/scoring_function/scoring_function_v0.1_only_strong/checkpoint_best_iteration3.ckpt'\n",
    "checkpoint = torch.load(checkpoint_PATH)\n",
    "checkpoint = remove_data_parallel(checkpoint['model_state_dict'])\n",
    "my_extended_model.load_state_dict(checkpoint, strict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c90e8a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "Image_dirs = []\n",
    "celltype_lists = []\n",
    "\n",
    "        \n",
    "pred_prob, pred_label, IDs = eval_scores(my_extended_model, imgdirs, cell_types_df, transform_pipeline,\n",
    "                                             named_celltype=named_celltype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c6140923",
   "metadata": {},
   "outputs": [],
   "source": [
    "def processing(x):\n",
    "    if x < 0.9:\n",
    "        return min(0.01,x)\n",
    "    else:\n",
    "        assert x>= 0.90, 'wrong'\n",
    "        if x >0.99:\n",
    "            return 0.1 + 9 * (x - 0.9)\n",
    "        else: \n",
    "            return 0.1 + 5 * (x - 0.9)\n",
    "        \n",
    "scores=pred_prob['True'].tolist()\n",
    "Image_dirs=IDs\n",
    "celltype_lists = named_celltype\n",
    "\n",
    "df = pd.DataFrame([], columns=['image_dirs','expert_scores'])\n",
    "df['image_dirs'] = Image_dirs\n",
    "df['expert_scores'] = scores\n",
    "rewards = []\n",
    "rewards = [processing(x) for x in scores]\n",
    "df['rewards'] = rewards\n",
    "df['celltype'] = celltype_lists\n",
    "df['ID'] = df['image_dirs'].str.split('/').str[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6ebd5e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../dm_hemedata/expert_scores_FinetunedModel_v0.1onlyStrong.tsv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da1dc09",
   "metadata": {},
   "source": [
    "#### 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "517a6283",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_extended_model = Myresnext50_algin(my_pretrained_model= resnext50_pretrained)\n",
    "checkpoint_PATH = '/data/aa-ssun2-cmp/improved-diffusion/Hemo_DL/scoring_function/scoring_function_v0.5_only_strong/checkpoint_best_iteration3.ckpt'\n",
    "checkpoint = torch.load(checkpoint_PATH)\n",
    "checkpoint = remove_data_parallel(checkpoint['model_state_dict'])\n",
    "my_extended_model.load_state_dict(checkpoint, strict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "689be61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "Image_dirs = []\n",
    "celltype_lists = []\n",
    "\n",
    "        \n",
    "pred_prob, pred_label, IDs = eval_scores(my_extended_model, imgdirs, cell_types_df, transform_pipeline,\n",
    "                                             named_celltype=named_celltype)\n",
    "\n",
    "scores=pred_prob['True'].tolist()\n",
    "Image_dirs=IDs\n",
    "celltype_lists = named_celltype\n",
    "\n",
    "df = pd.DataFrame([], columns=['image_dirs','expert_scores'])\n",
    "df['image_dirs'] = Image_dirs\n",
    "df['expert_scores'] = scores\n",
    "rewards = []\n",
    "rewards = [processing(x) for x in scores]\n",
    "df['rewards'] = rewards\n",
    "df['celltype'] = celltype_lists\n",
    "df['ID'] = df['image_dirs'].str.split('/').str[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fb16f49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../dm_hemedata/expert_scores_FinetunedModel_v0.5onlyStrong.tsv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1d531b",
   "metadata": {},
   "source": [
    "#### 100%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0e59f0d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_extended_model = Myresnext50_algin(my_pretrained_model= resnext50_pretrained)\n",
    "checkpoint_PATH = '/data/aa-ssun2-cmp/improved-diffusion/Hemo_DL/scoring_function/scoring_function_v1_only_strong/checkpoint_best_iteration3.ckpt'\n",
    "checkpoint = torch.load(checkpoint_PATH)\n",
    "checkpoint = remove_data_parallel(checkpoint['model_state_dict'])\n",
    "my_extended_model.load_state_dict(checkpoint, strict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5d9faead",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "Image_dirs = []\n",
    "celltype_lists = []\n",
    "\n",
    "        \n",
    "pred_prob, pred_label, IDs = eval_scores(my_extended_model, imgdirs, cell_types_df, transform_pipeline,\n",
    "                                             named_celltype=named_celltype)\n",
    "\n",
    "scores=pred_prob['True'].tolist()\n",
    "Image_dirs=IDs\n",
    "celltype_lists = named_celltype\n",
    "\n",
    "df = pd.DataFrame([], columns=['image_dirs','expert_scores'])\n",
    "df['image_dirs'] = Image_dirs\n",
    "df['expert_scores'] = scores\n",
    "rewards = []\n",
    "rewards = [processing(x) for x in scores]\n",
    "df['rewards'] = rewards\n",
    "df['celltype'] = celltype_lists\n",
    "df['ID'] = df['image_dirs'].str.split('/').str[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f10ce77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../dm_hemedata/expert_scores_FinetunedModel_v1.0onlyStrong.tsv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9caa152d",
   "metadata": {},
   "source": [
    "### Nromally what we did above is enough, but since now we need to rerun after merging M5 and M6, it's time to get some new results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "453dfe07",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_types = ['B1','B2','E1','E4','ER1','ER2','ER3','ER4','ER5','ER6', 'L2','L4', 'M1','M2','M3','M4','M5', 'M6', 'MO2', 'PL2','PL4','U1','U4',]\n",
    "cell_types.sort()\n",
    "\n",
    "\n",
    "cell_types_df = pd.DataFrame(cell_types, columns=['Cell_Types'])# converting type of columns to 'category'\n",
    "cell_types_df['Cell_Types'] = cell_types_df['Cell_Types'].astype('category')# Assigning numerical values and storing in another column\n",
    "cell_types_df['Cell_Types_Cat'] = cell_types_df['Cell_Types'].cat.codes\n",
    "\n",
    "\n",
    "\n",
    "enc = OneHotEncoder(handle_unknown='ignore')# passing bridge-types-cat column (label encoded values of bridge_types)\n",
    "enc_df = pd.DataFrame(enc.fit_transform(cell_types_df[['Cell_Types_Cat']]).toarray())# merge with main df bridge_df on key values\n",
    "cell_types_df = cell_types_df.join(enc_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49a0a572",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25230, 6)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../dm_hemedata/expert_scores_v1.tsv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53635680",
   "metadata": {},
   "outputs": [],
   "source": [
    "cellnames = [x.split('/')[-1] for x in glob.glob('/data/aa-ssun2-cmp/improved-diffusion/datasets/hemepath128_IMNF/*')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "707fab90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aa-ssun2-cmp/anaconda3/envs/heme_artist/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'B1',\n",
       " 'B2',\n",
       " 'E1',\n",
       " 'E4',\n",
       " 'ER1',\n",
       " 'ER2',\n",
       " 'ER3',\n",
       " 'ER4',\n",
       " 'ER5',\n",
       " 'ER6',\n",
       " 'M1',\n",
       " 'M2',\n",
       " 'M3',\n",
       " 'M4',\n",
       " 'M5',\n",
       " 'MO2'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_subset = df[df['celltype'].isin(cellnames+['M6'])]\n",
    "cell_lists = df_subset['celltype'].tolist()\n",
    "df_subset['celltype']  = [x.replace('M6','M5') for x in cell_lists]\n",
    "set(df_subset['celltype'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e57f7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Img_DataLoader_pair(data.Dataset):\n",
    "    def __init__(self, img_list='', in_dim=3, split='train', transform=False, in_size=96, df=None, encoder=None,\n",
    "                 if_external=False, df_features = None, named_celltype = None):\n",
    "        super(Img_DataLoader_pair, self).__init__()\n",
    "        self.split = split\n",
    "        self.in_dim = in_dim\n",
    "        self.transform = transform\n",
    "        self.filelist = img_list\n",
    "        self.in_size = in_size\n",
    "        self.file_paths = img_list\n",
    "        self.transform = transform\n",
    "        self.df = df\n",
    "        self.encoder = encoder\n",
    "        self.if_external = if_external\n",
    "        self.df_features = df_features\n",
    "        self.named_celltype = named_celltype\n",
    "    def __len__(self):\n",
    "        return len(self.file_paths)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        sample = dict()\n",
    "        img_path = self.file_paths[index]\n",
    "        high_level_name = self.named_celltype[index]\n",
    "        # prepare image\n",
    "        orig_img = cv2.imread(img_path)\n",
    "        image = cv2.cvtColor(orig_img, cv2.COLOR_BGR2RGB)\n",
    "        '''\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        image[:,:, 0] = gray\n",
    "        image[:,:, 1] = gray\n",
    "        image[:,:, 2] = gray\n",
    "        '''\n",
    "        ###################################\n",
    "\n",
    "        ###################################\n",
    "        if self.transform is not None:\n",
    "            try:\n",
    "                img = self.transform(image=image)[\"image\"]\n",
    "            except:\n",
    "                assert 1 == 2, 'something wrong'\n",
    "                print(image)\n",
    "\n",
    "        label = img_path.split('/')[-1].split('_')[0]\n",
    "        match = 1\n",
    "\n",
    "        # permutate\n",
    "        if named_celltype is not None:\n",
    "            \n",
    "            if label == named_celltype:\n",
    "                pass\n",
    "            else:\n",
    "                label = named_celltype\n",
    "                match = 0\n",
    "        else:          \n",
    "            permute = np.random.choice([0, 1])\n",
    "            lists = self.df['Cell_Types'].tolist()\n",
    "            if permute == 1:\n",
    "                lists.remove(label)\n",
    "\n",
    "                label = random.choice(lists)\n",
    "                match = 0\n",
    "            else:\n",
    "                pass\n",
    "        # print(img.shape)\n",
    "        #if self.if_external:\n",
    "        if img.shape[0]!=64:\n",
    "            img = img[16:80,16:80,:]\n",
    "        #img = cv2.resize(img, (64, 64), interpolation=cv2.INTER_AREA)\n",
    "        # img = img.reshape(3,96,96)\n",
    "        \n",
    "        img = np.einsum('ijk->kij', img)\n",
    "        \n",
    "        if self.split != \"compute\":  # Use compute if you only want the prediction results. if you do this, make sure you don't shuffle the data\n",
    "            mask = self.df[self.df['Cell_Types'] == high_level_name].iloc[:, 2:].to_numpy()\n",
    "            mask = mask.reshape(23,)\n",
    "            sample[\"label\"] = torch.from_numpy(mask).float()  # one hot encoder\n",
    "\n",
    "\n",
    "        sample[\"image\"] = torch.from_numpy(img).float()  # self.encoder(torch.from_numpy(img).float())\n",
    "        sample[\"ID\"] = img_path\n",
    "        sample[\"agree\"] = torch.from_numpy(np.array(match)).long()\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "809f4b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cp -r ../../improved-diffusion/dm_hemedata/Finetuned_dataset_v1 ../../improved-diffusion/dm_hemedata/Finetuned_dataset_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f2c246b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _dir in glob.glob('../../improved-diffusion/dm_hemedata/Finetuned_dataset_new/*'):\n",
    "    ID = _dir.split('/')[-1]\n",
    "    celltype = ID.split('_')[0]\n",
    "    if (celltype not in cellnames) and celltype !='M6':\n",
    "        os.remove(_dir)\n",
    "    elif celltype =='M6':\n",
    "        os.rename(_dir, _dir.replace('M6','M5'))\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6aaab2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "names  = glob.glob('../dm_hemedata/Finetuned_dataset_v1/M6_*')\n",
    "names = [x.split('/')[-1].replace('M6','M5') for x in names]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6022d527",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = '../dm_hemedata/Finetuned_dataset_new/'\n",
    "imgdirs = [folder+x+'_'+y for (x,y) in zip(df_subset['celltype'].tolist(), df_subset['ID'].tolist())]\n",
    "named_celltype = [x.split('/')[-1].split('_')[0] for x in imgdirs]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41afc5f",
   "metadata": {},
   "source": [
    "def processing(x):\n",
    "    if x < 0.9:\n",
    "        return min(0.01,x)\n",
    "    else:\n",
    "        assert x>= 0.90, 'wrong'\n",
    "        if x >0.99:\n",
    "            return 0.1 + 9 * (x - 0.9)\n",
    "        else: \n",
    "            return 0.1 + 5 * (x - 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bd10ddbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def processing(x):\n",
    "    return 1-x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "84ae0ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_test_orig = cellnames[cellnames['dir'].isin(X_test)]\n",
    "cell_types =['False', 'True']\n",
    "def eval_scores(model, test_lists, df, transform, label = None, named_celltype = None, computed_table= False):\n",
    "    model = model.cuda().eval()\n",
    "    Orig_img = Img_DataLoader_pair(img_list=  test_lists, split='viz',df= cell_types_df,transform = transform_pipeline,\n",
    "                                  named_celltype = named_celltype)\n",
    "    shuffle = False\n",
    "    dataloader = DataLoader(Orig_img, batch_size=32, num_workers=2, shuffle=shuffle)\n",
    "\n",
    "\n",
    "    for i, _batch in enumerate(dataloader):\n",
    "\n",
    "        if i == 0:\n",
    "\n",
    "            images = _batch[\"image\"].cuda()\n",
    "            label = _batch[\"label\"].cuda()\n",
    "            match = _batch['agree']\n",
    "            #print(label)\n",
    "            ID    = [x for x in _batch['ID']]\n",
    "            pred_prob = model(images, label)\n",
    "\n",
    "            pred_prob = torch.flatten(pred_prob, start_dim=1).detach().cpu().numpy()\n",
    "            label = match.numpy()  #, start_dim=1).cpu().numpy()\n",
    "        else:\n",
    "            images = _batch[\"image\"].cuda()\n",
    "            _label = _batch[\"label\"].cuda()\n",
    "            _match = _batch['agree']\n",
    "            _ID    = [x for x in _batch['ID']]\n",
    "            _pred_prob = model(images,_label)\n",
    "            \n",
    "\n",
    "            _pred_prob = torch.flatten(_pred_prob, start_dim=1).detach().cpu().numpy()\n",
    "            _label = _match.numpy()  #, start_dim=1).cpu().numpy()  \n",
    "\n",
    "            ID = ID + _ID\n",
    "            pred_prob = np.concatenate((pred_prob, _pred_prob))\n",
    "            label = np.concatenate((label, _label))\n",
    "    label = np.array(label)\n",
    "    _label = np.array(label==0)\n",
    "    label = np.stack([ _label,label])\n",
    "    label = label.T\n",
    "    \n",
    "    pred_prob = softmax(pred_prob, axis=1)\n",
    "    #pred_class_binary = np.where(res,np.max(res, axis =1))\n",
    "\n",
    "    for i in range(pred_prob.shape[0]):\n",
    "        if i == 0:\n",
    "            pred_class = np.where(pred_prob[i] == np.max(pred_prob[i]),1,0).reshape(1,2)\n",
    "        else:\n",
    "            _pred_class = np.where(pred_prob[i] == np.max(pred_prob[i]),1,0).reshape(1,2)\n",
    "            pred_class = np.concatenate((pred_class, _pred_class), axis =0)\n",
    "    \n",
    "    ID = [x for x in ID]\n",
    "    print(pred_prob.shape)\n",
    "    print(pred_class.shape)\n",
    "    pred_class = pd.DataFrame.from_records(pred_class, \n",
    "                                       columns= cell_types,\n",
    "                                      index = ID)\n",
    "    pred_prob = pd.DataFrame.from_records(pred_prob, \n",
    "                                           columns= cell_types,\n",
    "                                          index = ID)\n",
    "    label = pd.DataFrame.from_records(label, \n",
    "                                           columns= cell_types,\n",
    "                                          index = ID)\n",
    "    \n",
    "    if computed_table:\n",
    "        multiclass = evaluation_metrics_multiclass(label, pred_prob, pred_class)\n",
    "\n",
    "        #multiclass = evaluation_metrics_multiclass(label, pred_prob, pred_class)\n",
    "\n",
    "        df = pd.DataFrame.from_dict(multiclass)\n",
    "        df.index = ['AUC','F1','Acc','Precision','Recall']\n",
    "        df = df.T\n",
    "        df_summary = df.copy()\n",
    "        df_summary.loc['Mean'] = np.average(df, axis =0)\n",
    "        df_summary.loc['Medium'] = np.median(df, axis =0)\n",
    "        return df_summary, pred_class,pred_prob,label\n",
    "    else:\n",
    "        ### only logis\n",
    "        return pred_prob, label, ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ee131b78",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18702, 2)\n",
      "(18702, 2)\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "Image_dirs = []\n",
    "celltype_lists = []\n",
    "\n",
    "\n",
    "        \n",
    "pred_prob, pred_label, IDs = eval_scores(my_extended_model, imgdirs, cell_types_df, transform_pipeline,\n",
    "                                             named_celltype=named_celltype)\n",
    "\n",
    "scores=pred_prob['True'].tolist()\n",
    "Image_dirs=IDs\n",
    "celltype_lists = named_celltype\n",
    "\n",
    "df = pd.DataFrame([], columns=['image_dirs','expert_scores'])\n",
    "df['image_dirs'] = Image_dirs\n",
    "df['expert_scores'] = scores\n",
    "rewards = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "add1385c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rewards = [processing(x) for x in scores]\n",
    "df['rewards'] = rewards\n",
    "df['celltype'] = celltype_lists\n",
    "df['ID'] = df['image_dirs'].str.split('/').str[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e38b4ac8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18702, 5)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "59597f47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_dirs</th>\n",
       "      <th>expert_scores</th>\n",
       "      <th>rewards</th>\n",
       "      <th>celltype</th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10808</th>\n",
       "      <td>../dm_hemedata/Finetuned_dataset_new/ER6_BBDhk...</td>\n",
       "      <td>0.863726</td>\n",
       "      <td>0.136274</td>\n",
       "      <td>ER6</td>\n",
       "      <td>ER6_BBDhkhCTaK.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10807</th>\n",
       "      <td>../dm_hemedata/Finetuned_dataset_new/ER6_mZSNW...</td>\n",
       "      <td>0.854913</td>\n",
       "      <td>0.145087</td>\n",
       "      <td>ER6</td>\n",
       "      <td>ER6_mZSNWZvPsf.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10467</th>\n",
       "      <td>../dm_hemedata/Finetuned_dataset_new/ER6_PGfKv...</td>\n",
       "      <td>0.845816</td>\n",
       "      <td>0.154184</td>\n",
       "      <td>ER6</td>\n",
       "      <td>ER6_PGfKvbzwpA.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10825</th>\n",
       "      <td>../dm_hemedata/Finetuned_dataset_new/ER6_YRodY...</td>\n",
       "      <td>0.839455</td>\n",
       "      <td>0.160545</td>\n",
       "      <td>ER6</td>\n",
       "      <td>ER6_YRodYKKKae.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9960</th>\n",
       "      <td>../dm_hemedata/Finetuned_dataset_new/ER6_uKBNq...</td>\n",
       "      <td>0.833062</td>\n",
       "      <td>0.166938</td>\n",
       "      <td>ER6</td>\n",
       "      <td>ER6_uKBNqeHvqS.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10720</th>\n",
       "      <td>../dm_hemedata/Finetuned_dataset_new/ER6_asPUF...</td>\n",
       "      <td>0.191764</td>\n",
       "      <td>0.808236</td>\n",
       "      <td>ER6</td>\n",
       "      <td>ER6_asPUFJbzBQ.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10192</th>\n",
       "      <td>../dm_hemedata/Finetuned_dataset_new/ER6_TvWWA...</td>\n",
       "      <td>0.135631</td>\n",
       "      <td>0.864369</td>\n",
       "      <td>ER6</td>\n",
       "      <td>ER6_TvWWAQyAMm.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9928</th>\n",
       "      <td>../dm_hemedata/Finetuned_dataset_new/ER6_wVByE...</td>\n",
       "      <td>0.112405</td>\n",
       "      <td>0.887595</td>\n",
       "      <td>ER6</td>\n",
       "      <td>ER6_wVByEAuNyt.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10077</th>\n",
       "      <td>../dm_hemedata/Finetuned_dataset_new/ER6_BmfbR...</td>\n",
       "      <td>0.068715</td>\n",
       "      <td>0.931285</td>\n",
       "      <td>ER6</td>\n",
       "      <td>ER6_BmfbRJBXqV.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10298</th>\n",
       "      <td>../dm_hemedata/Finetuned_dataset_new/ER6_VjZAz...</td>\n",
       "      <td>0.065013</td>\n",
       "      <td>0.934987</td>\n",
       "      <td>ER6</td>\n",
       "      <td>ER6_VjZAzRlSPh.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1088 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              image_dirs  expert_scores  \\\n",
       "10808  ../dm_hemedata/Finetuned_dataset_new/ER6_BBDhk...       0.863726   \n",
       "10807  ../dm_hemedata/Finetuned_dataset_new/ER6_mZSNW...       0.854913   \n",
       "10467  ../dm_hemedata/Finetuned_dataset_new/ER6_PGfKv...       0.845816   \n",
       "10825  ../dm_hemedata/Finetuned_dataset_new/ER6_YRodY...       0.839455   \n",
       "9960   ../dm_hemedata/Finetuned_dataset_new/ER6_uKBNq...       0.833062   \n",
       "...                                                  ...            ...   \n",
       "10720  ../dm_hemedata/Finetuned_dataset_new/ER6_asPUF...       0.191764   \n",
       "10192  ../dm_hemedata/Finetuned_dataset_new/ER6_TvWWA...       0.135631   \n",
       "9928   ../dm_hemedata/Finetuned_dataset_new/ER6_wVByE...       0.112405   \n",
       "10077  ../dm_hemedata/Finetuned_dataset_new/ER6_BmfbR...       0.068715   \n",
       "10298  ../dm_hemedata/Finetuned_dataset_new/ER6_VjZAz...       0.065013   \n",
       "\n",
       "        rewards celltype                  ID  \n",
       "10808  0.136274      ER6  ER6_BBDhkhCTaK.png  \n",
       "10807  0.145087      ER6  ER6_mZSNWZvPsf.png  \n",
       "10467  0.154184      ER6  ER6_PGfKvbzwpA.png  \n",
       "10825  0.160545      ER6  ER6_YRodYKKKae.png  \n",
       "9960   0.166938      ER6  ER6_uKBNqeHvqS.png  \n",
       "...         ...      ...                 ...  \n",
       "10720  0.808236      ER6  ER6_asPUFJbzBQ.png  \n",
       "10192  0.864369      ER6  ER6_TvWWAQyAMm.png  \n",
       "9928   0.887595      ER6  ER6_wVByEAuNyt.png  \n",
       "10077  0.931285      ER6  ER6_BmfbRJBXqV.png  \n",
       "10298  0.934987      ER6  ER6_VjZAzRlSPh.png  \n",
       "\n",
       "[1088 rows x 5 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['celltype']=='ER6'].sort_values(by=['rewards'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "902723cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 207., 1859., 6031., 2796., 1709., 1539., 2249., 2058.,  197.,\n",
       "          57.]),\n",
       " array([0.01449531, 0.11244971, 0.21040411, 0.3083585 , 0.4063129 ,\n",
       "        0.50426729, 0.60222169, 0.70017609, 0.79813048, 0.89608488,\n",
       "        0.99403928]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(df['rewards'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "97b750e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../artifial_data/expert_scores_FinetunedModel_v1.0_refined.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e3b0caa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "names_real = [x.split('/')[-1].replace('M6','M5') for x in glob.glob('../datasets_old/hemepath_128_imageNet/M6/*')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4d5c3368",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../dm_hemedata/names.tsv','w') as F:\n",
    "    for i in names:\n",
    "        F.write(i+'\\n')\n",
    "    for i in names_real:\n",
    "        F.write(i+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a218dbcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "M6_IDs = []\n",
    "with open('../dm_hemedata/names.tsv','r') as F:\n",
    "    lines = F.readlines()\n",
    "    for _line in lines:\n",
    "        M6_IDs.append(_line.replace('\\n',''))\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dd55eba6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'M5_6994.png'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M6_IDs[-1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
